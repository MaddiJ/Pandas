{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyCity Schools Analysis\n",
    "\n",
    "* As a whole, schools with higher budgets, did not yield better test results. By contrast, schools with higher spending 645-675 per student actually underperformed compared to schools with smaller budgets (585 per student).\n",
    "\n",
    "* As a whole, smaller and medium sized schools dramatically out-performed large sized schools on passing math performances (89-91% passing vs 67%).\n",
    "\n",
    "* As a whole, charter schools out-performed the public district schools across all metrics. However, more analysis will be required to glean if the effect is due to school practices or the fact that charter schools tend to serve smaller student populations per school. \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Resources\\\\schools_complete.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17480\\3041409568.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# Read School and Student Data File and store into Pandas DataFrames\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mschool_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mschool_data_to_load\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[0mstudent_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstudent_data_to_load\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    676\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 678\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 575\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    576\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    577\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    930\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 932\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    933\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    934\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1214\u001b[0m             \u001b[1;31m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1215\u001b[0m             \u001b[1;31m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1216\u001b[1;33m             self.handles = get_handle(  # type: ignore[call-overload]\n\u001b[0m\u001b[0;32m   1217\u001b[0m                 \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1218\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    784\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m\"b\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    785\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 786\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    787\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Resources\\\\schools_complete.csv'"
     ]
    }
   ],
   "source": [
    "# Dependencies and Setup\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "# File to Load (Remember to Change These)\n",
    "school_data_to_load = Path(\"Resources/schools_complete.csv\")\n",
    "student_data_to_load = Path(\"Resources/students_complete.csv\")\n",
    "\n",
    "# Read School and Student Data File and store into Pandas DataFrames\n",
    "school_data = pd.read_csv(school_data_to_load)\n",
    "student_data = pd.read_csv(student_data_to_load)\n",
    "\n",
    "# Combine the data into a single dataset.  \n",
    "school_data_complete = pd.merge(student_data, school_data, how=\"left\", on=[\"school_name\", \"school_name\"])\n",
    "school_data_complete.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## District Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the total number of unique schools\n",
    "school_count = school_data_complete[\"school_name\"].nunique()\n",
    "school_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the total number of students\n",
    "student_count = school_data_complete[\"Student ID\"].nunique()\n",
    "student_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the total budget\n",
    "total_budget = school_data_complete[\"budget\"].sum\n",
    "total_budget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the average (mean) math score\n",
    "average_math_score = school_data_complete[\"math_score\"].mean()\n",
    "average_math_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the average (mean) reading score\n",
    "average_reading_score =school_data_complete[\"reading_score\"].mean()\n",
    "average_reading_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the following to calculate the percentage of students who passed math (math scores greather than or equal to 70)\n",
    "passing_math_count = school_data_complete[(school_data_complete[\"math_score\"] >= 70)].count()[\"student_name\"]\n",
    "passing_math_percentage = passing_math_count / float(student_count) * 100\n",
    "passing_math_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the percentage of students who passeed reading (hint: look at how the math percentage was calculated)  \n",
    "passing_reading_count =len(school_data_complete[school_data_complete[\"reading_score\"] >= 70])\n",
    "passing_reading_percentage =passingReading / totalStudents * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the following to calculate the percentage of students that passed math and reading\n",
    "passing_math_reading_count = school_data_complete[\n",
    "    (school_data_complete[\"math_score\"] >= 70) & (school_data_complete[\"reading_score\"] >= 70)\n",
    "].count()[\"student_name\"]\n",
    "overall_passing_rate = passing_math_reading_count /  float(student_count) * 100\n",
    "overall_passing_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a high-level snapshot of the district's key metrics in a DataFrame\n",
    "district_summary =  pd.DataFrame({\n",
    "    \"Total Schools\": [totalSchools],\n",
    "    \"Total Students\": [totalStudents],\n",
    "    \"Total Budget\": [totalBudget],\n",
    "    \"Average Math Score\": [averageMathScore],\n",
    "    \"Average Reading Score\": [averageReadingScore],\n",
    "    \"% Passing Math\": [percentagePassingMath],\n",
    "    \"% Passing Reading\": [percentagePassingReading],\n",
    "    \"% Overall Passing Rate\": [percentageOverallPassingRate]\n",
    "})\n",
    "\n",
    "# Formatting\n",
    "district_summary[\"Total Students\"] = district_summary[\"Total Students\"].map(\"{:,}\".format)\n",
    "district_summary[\"Total Budget\"] = district_summary[\"Total Budget\"].map(\"${:,.2f}\".format)\n",
    "\n",
    "# Display the DataFrame\n",
    "district_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## School Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the code provided to select the school type\n",
    "school_types = school_data.set_index([\"school_name\"])[\"type\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the total student count\n",
    "per_school_counts = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the total school budget and per capita spending\n",
    "per_school_budget = school_data_complete.groupby([\"school_name\"]).mean()[\"budget\"]\n",
    "per_school_capita = per_school_budget / per_school_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the average test scores\n",
    "per_school_math = \n",
    "per_school_reading = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the number of schools with math scores of 70 or higher\n",
    "school_passing_math = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the number of schools with reading scores of 70 or higher\n",
    "school_passing_reading = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the provided code to calculate the schools that passed both math and reading with scores of 70 or higher\n",
    "passing_math_and_reading = school_data_complete[\n",
    "    (school_data_complete[\"reading_score\"] >= 70) & (school_data_complete[\"math_score\"] >= 70)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the provided code to calculate the passing rates\n",
    "per_school_passing_math = school_passing_math.groupby([\"school_name\"]).count()[\"student_name\"] / per_school_counts * 100\n",
    "per_school_passing_reading = school_passing_reading.groupby([\"school_name\"]).count()[\"student_name\"] / per_school_counts * 100\n",
    "overall_passing_rate = passing_math_and_reading.groupby([\"school_name\"]).count()[\"student_name\"] / per_school_counts * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame called `per_school_summary` with columns for the calculations above.\n",
    "per_school_summary = \n",
    "\n",
    "# Formatting\n",
    "per_school_summary[\"Total School Budget\"] = per_school_summary[\"Total School Budget\"].map(\"${:,.2f}\".format)\n",
    "per_school_summary[\"Per Student Budget\"] = per_school_summary[\"Per Student Budget\"].map(\"${:,.2f}\".format)\n",
    "\n",
    "# Display the DataFrame\n",
    "per_school_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Highest-Performing Schools (by % Overall Passing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Sort the schools by `% Overall Passing` in descending order and display the top 5 rows.\n",
    "top_schools = \n",
    "top_schools.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bottom Performing Schools (By % Overall Passing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the schools by `% Overall Passing` in ascending order and display the top 5 rows.\n",
    "bottom_schools = \n",
    "bottom_schools.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Math Scores by Grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the code provided to separate the data by grade\n",
    "ninth_graders = school_data_complete[(school_data_complete[\"grade\"] == \"9th\")]\n",
    "tenth_graders = school_data_complete[(school_data_complete[\"grade\"] == \"10th\")]\n",
    "eleventh_graders = school_data_complete[(school_data_complete[\"grade\"] == \"11th\")]\n",
    "twelfth_graders = school_data_complete[(school_data_complete[\"grade\"] == \"12th\")]\n",
    "\n",
    "# Group by \"school_name\" and take the mean of each.\n",
    "ninth_graders_scores = \n",
    "tenth_graders_scores = \n",
    "eleventh_graders_scores = \n",
    "twelfth_graders_scores = \n",
    "\n",
    "# Use the code to select only the `math_score`.\n",
    "ninth_grade_math_scores = ninth_graders_scores[\"math_score\"]\n",
    "tenth_grader_math_scores = tenth_graders_scores[\"math_score\"]\n",
    "eleventh_grader_math_scores = eleventh_graders_scores[\"math_score\"]\n",
    "twelfth_grader_math_scores = twelfth_graders_scores[\"math_score\"]\n",
    "\n",
    "# Combine each of the scores above into single DataFrame called `math_scores_by_grade`\n",
    "math_scores_by_grade = \n",
    "\n",
    "# Minor data wrangling\n",
    "math_scores_by_grade.index.name = None\n",
    "\n",
    "# Display the DataFrame\n",
    "math_scores_by_grade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Score by Grade "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the code provided to separate the data by grade\n",
    "ninth_graders = school_data_complete[(school_data_complete[\"grade\"] == \"9th\")]\n",
    "tenth_graders = school_data_complete[(school_data_complete[\"grade\"] == \"10th\")]\n",
    "eleventh_graders = school_data_complete[(school_data_complete[\"grade\"] == \"11th\")]\n",
    "twelfth_graders = school_data_complete[(school_data_complete[\"grade\"] == \"12th\")]\n",
    "\n",
    "# Group by \"school_name\" and take the mean of each.\n",
    "ninth_graders_scores = \n",
    "tenth_graders_scores = \n",
    "eleventh_graders_scores = \n",
    "twelfth_graders_scores = \n",
    "\n",
    "# Use the code to select only the `reading_score`.\n",
    "ninth_grade_reading_scores = ninth_graders_scores[\"reading_score\"]\n",
    "tenth_grader_reading_scores = tenth_graders_scores[\"reading_score\"]\n",
    "eleventh_grader_reading_scores = eleventh_graders_scores[\"reading_score\"]\n",
    "twelfth_grader_reading_scores = twelfth_graders_scores[\"reading_score\"]\n",
    "\n",
    "# Combine each of the scores above into single DataFrame called `reading_scores_by_grade`\n",
    "reading_scores_by_grade = \n",
    "\n",
    "# Minor data wrangling\n",
    "reading_scores_by_grade = reading_scores_by_grade[[\"9th\", \"10th\", \"11th\", \"12th\"]]\n",
    "reading_scores_by_grade.index.name = None\n",
    "\n",
    "# Display the DataFrame\n",
    "reading_scores_by_grade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scores by School Spending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish the bins \n",
    "spending_bins = [0, 585, 630, 645, 680]\n",
    "labels = [\"<$585\", \"$585-630\", \"$630-645\", \"$645-680\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of the school summary since it has the \"Per Student Budget\" \n",
    "school_spending_df = per_school_summary.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use `pd.cut` to categorize spending based on the bins.\n",
    "school_spending_df[\"Spending Ranges (Per Student)\"] = \n",
    "school_spending_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Calculate averages for the desired columns. \n",
    "spending_math_scores = school_spending_df.groupby([\"Spending Ranges (Per Student)\"]).mean()[\"Average Math Score\"]\n",
    "spending_reading_scores = school_spending_df.groupby([\"Spending Ranges (Per Student)\"]).mean()[\"Average Reading Score\"]\n",
    "spending_passing_math = school_spending_df.groupby([\"Spending Ranges (Per Student)\"]).mean()[\"% Passing Math\"]\n",
    "spending_passing_reading = school_spending_df.groupby([\"Spending Ranges (Per Student)\"]).mean()[\"% Passing Reading\"]\n",
    "overall_passing_spending = school_spending_df.groupby([\"Spending Ranges (Per Student)\"]).mean()[\"% Overall Passing\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assemble into DataFrame\n",
    "spending_summary = \n",
    "\n",
    "# Display results\n",
    "spending_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scores by School Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish the bins.\n",
    "size_bins = [0, 1000, 2000, 5000]\n",
    "labels = [\"Small (<1000)\", \"Medium (1000-2000)\", \"Large (2000-5000)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorize the spending based on the bins\n",
    "# Use `pd.cut` on the \"Total Students\" column of the `per_school_summary` DataFrame.\n",
    "\n",
    "per_school_summary[\"School Size\"] = \n",
    "per_school_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate averages for the desired columns. \n",
    "size_math_scores = per_school_summary.groupby([\"School Size\"]).mean()[\"Average Math Score\"]\n",
    "size_reading_scores = per_school_summary.groupby([\"School Size\"]).mean()[\"Average Reading Score\"]\n",
    "size_passing_math = per_school_summary.groupby([\"School Size\"]).mean()[\"% Passing Math\"]\n",
    "size_passing_reading = per_school_summary.groupby([\"School Size\"]).mean()[\"% Passing Reading\"]\n",
    "size_overall_passing = per_school_summary.groupby([\"School Size\"]).mean()[\"% Overall Passing\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a DataFrame called `size_summary` that breaks down school performance based on school size (small, medium, or large).\n",
    "# Use the scores above to create a new DataFrame called `size_summary`\n",
    "size_summary = \n",
    "\n",
    "# Display results\n",
    "size_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scores by School Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the per_school_summary DataFrame by \"School Type\" and average the results.\n",
    "type_math_scores = \n",
    "type_reading_scores = \n",
    "type_passing_math = \n",
    "type_passing_reading = \n",
    "type_overall_passing = \n",
    "\n",
    "# Use the code provided to select new column data\n",
    "average_math_score_by_type = type_math_scores[\"Average Math Score\"]\n",
    "average_reading_score_by_type = type_reading_scores[\"Average Reading Score\"]\n",
    "average_percent_passing_math_by_type = type_passing_math[\"% Passing Math\"]\n",
    "average_percent_passing_reading_by_type = type_passing_reading[\"% Passing Reading\"]\n",
    "average_percent_overall_passing_by_type = type_overall_passing[\"% Overall Passing\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assemble the new data by type into a DataFrame called `type_summary`\n",
    "type_summary = \n",
    "\n",
    "# Display results\n",
    "type_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nteract": {
   "version": "0.8.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "5384d77d82de63fd599f73e77f9ec786e7719288bf80a29ec0288c670ac3cf32"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
